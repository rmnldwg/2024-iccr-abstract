[
  {
    "objectID": "content/manuscript.html",
    "href": "content/manuscript.html",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "",
    "text": "Head and neck squamous cell carcinomas (HNSCC) frequently spread through the lymphatic system (Lindberg 1972; Woolgar 1999). Current diagnostic imaging modalities are unable to detect microscopic lymph node metastases (Snyder et al. 2021; Strohl et al. 2021). To avoid nodal recurrences (Ho et al. 2014), large volumes in the neck are irradiated electively, which are at risk of harbouring occult disease. Guidelines about which lymph node levels (LNLs) to irradiate (Biau et al. 2019) are currently not based on a patient’s individual risk, but only on the overall prevalence of nodal disease as reported in the literature (Lindberg 1972; Woolgar 1999).\nTo personalize this prediction of the risk for occult disease, given a patient’s individual diagnosis, we published\n\nlarge, multi-centric data that reports per patient which LNLs where clinically and/or pathologically involved (Ludwig, Hoffmann, Pouymayou, Morand, et al. 2022; Ludwig et al. 2023).\n\nAnd, building on this work,\n\nan interpretable hidden Markov model (HMM), trained with this data, to predict the risk for occult nodal disease (Ludwig et al. 2021), given an individual patient’s diagnosis.\n\nSuch a personalized risk prediction may allow clinicians to safely reduce the elective clinical target volume (CTV-N) and thus reduce side-effects that degrade the patient’s quality of life (Batth, Caudell, and Chen 2014).\nHere, we extend the previous work by incorporating the primary tumor location (specified as ICD-10 code) into the model of lymphatic tumour progression, focusing on tumours in the oropharynx and the oral cavity. HNSCC patients with primary tumors at different subsites show different patterns of lymphatic spread (Lindberg 1972; Woolgar 1999). So far, this could be handled by training different models for broader categories of tumour locations, e.g. oropharynx and oral cavity tumours. However, this approach does not describe differences in lymphatic spread between different subsites within the oropharynx and oral cavity. To address this issue, we present an approach using mixtures of HMMs. The intuition is that the lymphatic spread of a tumor that lies anatomically at the boarder of oropharynx and oral cavity (e.g. tumours in the palate) may be described by a mixture of different models."
  },
  {
    "objectID": "content/manuscript.html#sec-hmm",
    "href": "content/manuscript.html#sec-hmm",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Hidden Markov Model for Lymphatic Progression",
    "text": "Hidden Markov Model for Lymphatic Progression\nA patient’s state of lymph node involvement \\(\\mathbf{X}[t]\\) evolves over discrete time steps \\(t\\). Let us enumerate all \\(2^V\\) possible states, representing all combinations of LNLs. In this paper, we consider ipsilateral LNLs I, II, III and IV, which amounts to 16 possible states. The HMM is specified by transition matrix \\(\\mathbf{A}\\):\n\\[\n\\mathbf{A} = \\begin{pmatrix} A_{ij} \\end{pmatrix} = P \\left( \\mathbf{X}[t+1] = \\boldsymbol{\\xi}_j \\mid \\mathbf{X}[t] = \\boldsymbol{\\xi}_i \\right)\n\\tag{2}\\]\nwhich contains the conditional probabilities that a state \\(\\mathbf{X}[t]=\\boldsymbol{\\xi}_i\\) transitions to \\(\\mathbf{X}[t+1]=\\boldsymbol{\\xi}_j\\) over one time step. The transition matrix is specified and parameterised via the graphical model shown in figure 1. The red arcs in the graph of figure 1 are associated the probability that the primary tumor spreads directly to a LNL (parameters \\(b_v\\)). The blue arcs describe the spread from an upstream LNL – given it is already metastatic – to a downstream level (parameters \\(t_{v-1 \\rightarrow v}\\)).\nNow, let \\(\\boldsymbol{\\pi}\\) be the starting distribution\n\\[\n\\boldsymbol{\\pi} = \\begin{pmatrix} \\pi_i \\end{pmatrix} = P \\left( \\mathbf{X}[0] = \\boldsymbol{\\xi}_i \\right)\n\\tag{3}\\]\ndenoting the probability to start in state \\(\\boldsymbol{\\xi}_i\\) at time step 0. Assuming that every patient started their disease with all LNLs being healthy, we set \\(\\pi_i\\) to zero for all states except the completly healthy state \\(\\boldsymbol{\\xi} = \\begin{pmatrix} 0, 0, 0, 0 \\end{pmatrix}\\), which has probability 1.\nUsing the quantities introduced so far, the probability \\(P \\left( \\mathbf{X}[t]=\\boldsymbol{\\xi}_i \\right)\\) to be in state \\(i\\) in time step \\(t\\) can now be conveniently expressed as a matrix product:\n\\[\nP \\left( \\mathbf{X}[t]=\\boldsymbol{\\xi}_i \\right) = \\left( \\boldsymbol{\\pi} \\cdot \\mathbf{A}^t \\right)_i\n\\tag{4}\\]\nThis evolution implicitly marginalizes over all possible paths to arrive at state \\(\\boldsymbol{\\xi}_i\\) after \\(t\\) time-steps. Additionally, we must marginalize over the unknown time of diagnosis using a time-prior \\(P(t)\\). This finally defines the probability distribution over all states of lymph node involvement used in equation 1.\n\\[\nP \\left( \\mathbf{X}=\\boldsymbol{\\xi}_i \\mid \\boldsymbol{\\theta} \\right) = \\sum_{t=0}^{t_\\text{max}} P_T(t) \\left( \\boldsymbol{\\pi} \\cdot \\mathbf{A}^t \\right)_i\n\\tag{5}\\]\nwhere \\(\\boldsymbol{\\theta}=\\{ b_v, t_{r \\rightarrow v} \\}\\) denotes the set of all model parameters (7 in our case). Fortunately, the exact length and shape of this distribution on its own has little impact as previously shown. We set \\(t_\\text{max}=\\) 10 and \\(P_\\text{early}(t)\\) to a binomial distribution with parameter 0.3. Further details on the HMM can be found in …\n\n\n\n\n\n\nFigure 1: On the left: Rough anatomical sketch of the tumor subsites and correspsonding ICD-10 codes that are present in the used data. The subsite “other parts of mouth” (C06) was not drawn. On the right: Parametrized graph representation of the lymphatic network considering four LNLs. Blue nodes represent the hidden RVs, while the red one is the tumor. Arcs represent a conditional probability parametrized with the quantity noted next to it"
  },
  {
    "objectID": "content/manuscript.html#sec-mixture-of-hmms",
    "href": "content/manuscript.html#sec-mixture-of-hmms",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Mixture of HMMs",
    "text": "Mixture of HMMs\nLet us now assume that primary tumors at different subsites have different patterns of lymphatic spread, corresponding to different model parameters \\(\\boldsymbol{\\theta}\\). Training a separate model for every possible subsite (ICD-10 code) would require a sufficiently large dataset for every tumor site. However, anatomically nearby locations are expected to show very similar patterns of LNL involvement. Therefore, we consider a mixture model.\nLet us assume that we have a dataset \\(\\mathbf{D}\\) that is specified via the number of patients \\(N_{is}\\) that were diagnosed in LNL involvement state \\(i\\) and had a primary tutor in subsite \\(s\\). Let us further assume that we want to describe this dataset using a mixture of \\(M\\) HMMs, each with a different set of model parameters \\(\\boldsymbol{\\theta_m}\\). As the generative model of the data, we assume that a patient with subsite \\(s\\) is generated with probability \\(\\pi_{sm}\\) from model \\(m\\). The likelihood of the dataset can then be written as\n\\[\nP \\left( \\mathbf{D} \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\pi}\\right) = \\prod_s \\prod_i \\left[ \\sum_{m=1}^M \\pi_{sm} P_m \\left( \\mathbf{X}=\\boldsymbol{\\xi}_i \\mid \\boldsymbol{\\theta}_m \\right) \\right]^{N_{is}}\n\\tag{6}\\]\nWe now have two types of parameters, the probabilities of tutor spread for the different models \\(\\boldsymbol{\\theta_m}\\), and the mixing coefficients \\(\\pi_{sm}\\). Assuming a uniform prior in the interval \\([0,1]\\) for all parameters, the posterior distribution over the parameters \\(P \\left( \\boldsymbol{\\theta}, \\boldsymbol{\\pi} \\mid \\mathbf{D} \\right)\\) is given by the likelihood equation 7 except for a normalisation constant. In this work, we use Markov chain Monte Carlo sampling (MCMC) via the emcee Python package (Foreman-Mackey et al. 2013) to sample model parameters from the posterior distribution. However, \\(P \\left( \\boldsymbol{\\theta}, \\boldsymbol{\\pi} \\mid \\mathbf{D} \\right)\\) itself is a multi-model distribution because one can permute the different models. To address this problem, we revert to an expectation-maximization (EM) algorithm where we iteratively sample model parameters \\(\\boldsymbol{\\theta_m}\\) using MCMC and then determine the most likely mixing coefficients.\n…\nThe just introduced model is capable of learning one set of or distribution over parameters \\(\\boldsymbol{\\theta}\\) from a cohort of patients with a primary tumor in a given subsite. If we tried to train it with a cohort consisting of patients with tumors in two very different subsites, the model would likely learn parameters that represent a compromise between the two subcohort’s true parameters. This compromise might describe neither of the subcohorts’ lymphatic spread patterns sufficiently well.\nIn such cases, mixture models are often considered. They assume the data to come from a finite mixture distribution, which – in our particular case – can be written as follows:\n\\[\nP \\left( \\mathbf{D} \\mid \\boldsymbol{\\Psi} \\right) = \\sum_{j=0}^g c_j P \\left( \\mathbf{D} \\mid \\boldsymbol{\\theta}_j \\right)\n\\tag{7}\\]\nHere, the \\(\\mathbf{c} \\in [0,1]^g\\) is the vector of mixing proportions with \\(\\sum_{j=0}^g c_j = 1\\), while the \\(\\boldsymbol{\\Psi} = \\left( \\boldsymbol{\\theta}_1, \\ldots, \\boldsymbol{\\theta}_g\\right)\\) is the vector of all \\(g\\) models’ parameters. Note that we will implement our model such that some of the parameters in each \\(\\boldsymbol{\\theta}_j\\) are shared across the \\(g\\) components – namely the \\(t_{r \\rightarrow v}\\) corresponding to the blue arcs in figure 1.\nLet now \\(\\mathfrak{D} = \\left( \\mathbf{D}_1, \\ldots, \\mathbf{D}_s \\right)\\) be a dataset consisting of \\(s\\) subcohorts of patients. Within a subcohort \\(i\\) we find \\(N_i\\) patients with tumors in the same subsite. We can then introduce a latent variable \\(\\mathbf{Z}\\) with a one-hot-encoding: Basically, it can take on values \\(\\mathbf{z}_i \\in \\{ 0,1 \\}^g\\) with \\(z_{ij}=1\\) if subcohort \\(i\\) belongs to component \\(j\\) and \\(z_{ij}=0\\) else.\nThe latent variables are helpful in resolving the invariance of the likelihood w.r.t. permutations of the component labels, which may introduce problems, e.g. for common MCMC sampling methods. The \\(\\mathbf{Z}\\) allows us to derive two sets of interdependent equations that we may solve in an iterative fashion (see e.g. Bishop (2006) for a detailed derivation) that is commonly referred to as expectation-maximization (EM) algorithm:\nThe first set are the probabilities of subcohort \\(i\\) to belong to component \\(j\\), given a set of parameters \\(\\boldsymbol{\\Psi}^\\star\\). These are often called the responsibilities: \\[\n\\gamma (z_{ij}) = P \\left( z_{ij}=1 \\mid \\mathbf{D}_i , \\boldsymbol{\\Psi}^\\star, \\mathbf{c} \\right) = \\frac{ c_j P \\left( \\mathbf{D}_i \\mid \\boldsymbol{\\theta}_j^\\star \\right) }{\\sum_{k=0}^g c_k P \\left( \\mathbf{D}_i \\mid \\boldsymbol{\\theta}_k^\\star \\right)}\n\\]\nFrom this, we can compute new mixing proportions \\(c_j^\\star=\\sum_{i=1}^s \\gamma (z_{ij}) / s\\) and then infer new parameters \\(\\boldsymbol{\\Psi}^\\star\\) – e.g. via MCMC sampling – from the resulting likelihood, which is the second set:\n\\[\nP \\left( \\mathbf{D} \\mid \\boldsymbol{\\Psi}, \\mathbf{c}^\\star \\right) = \\sum_{j=0}^g c_j^\\star P \\left( \\mathbf{D} \\mid \\boldsymbol{\\theta}_j \\right)\n\\]"
  },
  {
    "objectID": "content/manuscript.html#sec-implementation",
    "href": "content/manuscript.html#sec-implementation",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Implementation",
    "text": "Implementation\nWe did this in this and that fashion…"
  },
  {
    "objectID": "content/manuscript.html#multi-centric-data",
    "href": "content/manuscript.html#multi-centric-data",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Multi-Centric Data",
    "text": "Multi-Centric Data\nFor the analyses in this work, we used five datasets from four different institutions:\n\n287 oropharyngeal patients from the University of Zurich in Swizerland\n263 oropharyngeal patients from the Centre Léon Bérard in Fance\n289 oropharyngeal and oral cavity patients from the Inselspital Bern in Swizerland\n239 oropharyngeal and oral cavity patients from the Centre Léon Bérard in Fance\n162 oropharyngeal patients from the Hospital Vall d’Hebron in Spain\n\n\n\n\n\n\n\nFigure 2: Prevalence of LNL involvement stratified by subsite. The subsites are sorted in ascending order by their prevalence of involvement in LNL II. Oral cavity subsites are plotted in shaed of blue, oropharynx subsites in shades of orange.\n\n\n\nThe data comes in the form of CSV tables and are – except for the last and most recent addition – publicly available (Ludwig, Hoffmann, Pouymayou, Däppen, et al. 2022; Ludwig et al. 2023) and may be interactively explored in our Lymphatic Progression eXplorer LyProX. Each row of these tables corresponds to one patient and details in which LNL metastatic involvement was found or not, according to different diagnostic and pathologic modalities.\nIn figure 2, we have plotted the prevalence of involvement in the four LNLs I, II, III, and IV stratified by the primary tumor’s subsite. We only included patients with tumors in the gum, floor of mouth, other/unspecified parts of the mouth, palate, oropharynx, tosil, base of tongue, and other/unspecified parts of tongue, resulting in 1242 patients."
  }
]