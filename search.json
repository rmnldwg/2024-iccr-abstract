[
  {
    "objectID": "content/manuscript.html",
    "href": "content/manuscript.html",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "",
    "text": "Head and neck squamous cell carcinomas (HNSCC) frequently spread through the lymphatic system (Lindberg 1972; Woolgar 1999). Current diagnostic imaging modalities are unable to detect microscopic nodal metastases, which requires pathological examination of extracted tissue (Snyder et al. 2021; Strohl et al. 2021). Since the recurrence of nodal disease is detrimental to a patient’s outcome (Ho et al. 2014), large volumes in the head and neck region are often irradiated electively to minimize the risk of missing occult disease. Decision guidelines about which nodal regions – i.e., anatomically defined lymph node levels (LNLs) – to irradiate (Biau et al. 2019) are currently not based on a patient’s individual risk, but only on the overall prevalence of nodal disease as reported in the literature (Lindberg 1972; Woolgar 1999).\nTo personalize this prediction of the risk for occult diease, given a patient’s individual diagnosis, we published\n\nlarge, multi-centric data that reports per patient which LNLs where clinically and/or pathologically involved (Ludwig, Hoffmann, Pouymayou, Morand, et al. 2022; Ludwig et al. 2023).\n\nAnd, building on this work,\n\nan interpretable hidden Markov model (HMM), trained with this data, to predict the risk for occult nodal disease (Ludwig et al. 2021), given an individual patient’s diagnosis.\n\nSuch a personalized risk prediction may allow clinitians to safely reduce the elective clinical target volume (CTV-N) and thus reduce side-effects that degrade the patient’s quality of life (Batth, Caudell, and Chen 2014).\nHNSCC patients with primary tumors at different subsites, e.g. in the oral cavity and in the oropharynx, also show different patterns of lymphatic spread (Lindberg 1972; Woolgar 1999). Our model does so far not have the capability to naturally describe different tumor subsites. To that end, we present an approach using mixtures of these HMMs in this work. This makes intuitive sense, because if a tumor lies anatomically between two anatomically close subsites with slightly different spread patterns, we may be able to describe its lymphatic progression as a mixture of these two spread patterns."
  },
  {
    "objectID": "content/manuscript.html#sec-hmm",
    "href": "content/manuscript.html#sec-hmm",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Hidden Markov Model for Lymphatic Progression",
    "text": "Hidden Markov Model for Lymphatic Progression\nEach LNL \\(v \\in \\{ 1, 2, \\ldots, V\\}\\) considered in our model is represented by a binary random variable (RV) \\(X_v[t]\\) taking on the true state of that level at the abstract time-step \\(t\\) (0 for “healthy” and 1 for “involved”). Collected in a random vector \\(\\mathbf{X}[t] = \\left( X_1[t], X_2[t], \\ldots, X_V[t] \\right)\\) they form the patient’s state w.r.t. their lymphatic involvement at time \\(t\\).\nWe model the process of tumor progression via lymphatic drainage by connecting the RVs in a graph, as shown in figure 1. The arcs in this graph represent conditional probabilities. The orange arcs correspond to observing a diagnosis \\(Y_v\\), given the true state \\(X_v\\). For the sake of brevity, we will not go into the details of describing how to infer the true – but technically hidden – state of LNL involvement from diagnoses with lower-than-one sensitivity and specificity. This description can be found in Ludwig (2023). Throughout this work, we instead combine diagnostic and pathologic involvement information from the data into a “maximum likelihood” diagnosis and assume its sensitivity and specificity to be one, meaning the normally hidden state \\(X_v\\) becomes the observed state. This simplification is reasonable for pathologic involvement and because we are at this stage more interested in testing whether our model is able to describe a realistic probability distribution over lymphatic involvement.\nThe red arcs in the graph of figure 1 depict the probability that the primary tumor spreads within one abstract time-step. While the blue arcs symbolize the spread from an upstream LNL – given it is already metastatic – to a downstream level. For example, the edge from \\(X_2\\) to \\(X_3\\) encodes the probability \\(P\\left( X_3[t+1] \\mid X_2[t] \\right)\\), which is parametrized with \\(b_3\\), and \\(t_{2 \\rightarrow 3}\\) and tabulated in table 1. There is an additional restriction on any LNL’s state \\(X_v[t+1]=0\\) to be healthy: It requires that the level was also healthy in the time-step before, meaning \\(X_v[t]=0\\). This is because we assume no spontaneous self-healing of metastatic levels.\n\n\n\nTable 1: Conditional probability \\(P\\left( X_3[t+1] \\mid X_2[t] \\right)\\) for a spread from LNL II to III during the transition from \\(t\\) to \\(t+1\\). This corresponds to one of the blue arcs in figure 1. Note that the values in the row with \\(X_3[t+1]=0\\) is all zeros, and the row with \\(X_3[t+1]=1\\) all ones if \\(X_3[t]=1\\).\n\n\n\n\n\n\n\n\n\n\n\n\\(X_2[t]=0\\)\n\\(X_2[t]=1\\)\n\n\n\n\n\\(X_3[t+1]=0\\)\n\\(1-b_3\\)\n\\((1-b_3)(1-t_{2 \\rightarrow 3})\\)\n\n\n\\(X_3[t+1]=1\\)\n\\(b_3\\)\n\\(1-b_3-t_{2 \\rightarrow 3}+b_3 t_{2 \\rightarrow 3}\\)\n\n\n\n\n\n\nWith the introduced conditional probabilities, we can now compute the joint probability of any complete state \\(\\mathbf{X}[t]=\\boldsymbol{\\xi}_i\\) transitioning to any other possible state \\(\\mathbf{X}[t+1]=\\boldsymbol{\\xi}_j\\). Here, when we use \\(\\boldsymbol{\\xi}\\) instead of \\(\\mathbf{x}\\) for the values the random vector \\(\\mathbf{X}\\) can take on, the \\(i\\) and \\(j\\) enumerate all \\(2^V\\) combinations of the \\(V\\) binary RVs. In the graph shown in figure 1, this amounts to \\(2^V=8\\) distinct \\(\\boldsymbol{\\xi}_i\\). Because these terms are essentially products of terms like those in table 1. We can then collect these terms in a transition matrix \\(\\mathbf{A}\\):\n\\[\n\\mathbf{A} = \\begin{pmatrix} A_{ij} \\end{pmatrix} = P \\left( \\mathbf{X}[t+1] = \\boldsymbol{\\xi}_j \\mid \\mathbf{X}[t] = \\boldsymbol{\\xi}_i \\right)\n\\tag{2}\\]\nNote that this matrix still depends on the \\(b_v\\) and \\(t_{r \\rightarrow v}\\) parameters, although we have dropped the explicit dependcy to keep the equations brief. Now, assuming that every patient started their disease with all LNLs being healthy, we can define the starting distribution \\(\\boldsymbol{\\pi}\\):\n\\[\n\\boldsymbol{\\pi} = \\begin{pmatrix} \\pi_i \\end{pmatrix} = P \\left( \\mathbf{X}[0] = \\boldsymbol{\\xi}_i \\right)\n\\tag{3}\\]\nAnd set every entry of this starting distribution to zero, except the first one, which we set to one. This means at \\(t=0\\) there is a probability of one to be in the completly healthy state \\(\\boldsymbol{\\xi}_0 = \\begin{pmatrix} 0, 0, \\ldots, 0 \\end{pmatrix}\\).\nUsing the quantities introduced so far, the probability distribution vector with elements \\(P \\left( \\mathbf{X}[t]=\\boldsymbol{\\xi}_i \\right)\\) after \\(t\\) time-steps can now be conveniently expressed as a matrix product:\n\\[\nP \\left( \\mathbf{X}[t]=\\boldsymbol{\\xi}_i \\right) = \\left( \\boldsymbol{\\pi} \\cdot \\mathbf{A}^t \\right)_i\n\\tag{4}\\]\nThis evolution implicitly marginalizes over all possible paths to arrive at state \\(\\boldsymbol{\\xi}_i\\) after \\(t\\) time-steps. Additionally, we also need to marginalize over the time of diagnosis – which is unknown – using a time-prior \\(P_T(t)\\). Fortunately, the exact length and shape of this distribution on its own has little impact. But because we assume that early and advanced T-category patients are fundamentally the same, just on average diagnosed at different times \\(t\\), we use the time-prior only to separate the respective patient’s evolutions:\n\\[\nP \\left( \\mathbf{X}=\\boldsymbol{\\xi}_i \\mid T, \\boldsymbol{\\theta} \\right) = \\sum_{t=0}^{t_\\text{max}} P_T(t) \\left( \\boldsymbol{\\pi} \\cdot \\mathbf{A}^t \\right)_i\n\\tag{5}\\]\nwhere \\(T \\in \\{ \\text{early}, \\text{advanced} \\}\\) denotes the T-category. We fix \\(P_\\text{early}(t)\\) to a binomial distribution with parameters \\(n=t_\\text{max}=\\) 10 and \\(p_\\text{early}=\\) 0.3, while the advanced T-category’s time-prior is also a binomial distribution where the \\(p_\\text{advanced}\\) parameter is learned.\nNote that equation 5 still depends on the parametrization of the transition matrix. We collect these parameters in a vector \\(\\boldsymbol{\\theta}=\\{ b_v, t_{r \\rightarrow v}, p_\\text{advanced} \\}\\).\nTo train our model, we need to compute the likelihood of a dataset \\(\\mathbf{D}=\\left( \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_N \\right)\\) of \\(N\\) patients, given the model’s parameters \\(\\boldsymbol{\\theta}\\). This is given by a product of the terms in equation 5:\n\\[\nP \\left(\\mathbf{D} \\mid \\boldsymbol{\\theta} \\right) = \\prod_{i=1}^N P \\left( \\mathbf{X} = \\mathbf{x}_i \\mid T_i, \\boldsymbol{\\theta} \\right)\n\\tag{6}\\]\nTypically, one would compute the logarithm of this quantity for computational reasons. There is a wide array of available methods to obtain maximum likelihood estimates from this function or sample from the posterior over \\(\\boldsymbol{\\theta}\\). In this work, we use Markov chain Monte Carlo sampling (MCMC) via the emcee Python package (Foreman-Mackey et al. 2013).\n\n\n\n\n\n\nFigure 1: Parametrized graph representation of the lymphatic network considering four LNLs. Blue, round nodes represent the hidden RVs, while orange square nodes show the observed RVs. Arcs represent a conditional probability parametrized with the quantity noted next to it."
  },
  {
    "objectID": "content/manuscript.html#sec-mixture-of-hmms",
    "href": "content/manuscript.html#sec-mixture-of-hmms",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Mixture of HMMs",
    "text": "Mixture of HMMs\nThe just introduced model is capable of learning one set of or distribution over parameters \\(\\boldsymbol{\\theta}\\) from a cohort of patients with a primary tumor in a given subsite. If we tried to train it with a cohort consisting of patients with tumors in two very different subsites, the model would likely learn parameters that represent a compromise between the two subcohort’s true parameters. This compromise might describe neither of the subcohorts’ lymphatic spread patterns sufficiently well.\nIn such cases, mixture models are often considered. They assume the data to come from a finite mixture distribution, which – in our particular case – can be written as follows:\n\\[\nP \\left( \\mathbf{D} \\mid \\boldsymbol{\\Psi} \\right) = \\sum_{j=0}^g c_j P \\left( \\mathbf{D} \\mid \\boldsymbol{\\theta}_j \\right)\n\\tag{7}\\]\nHere, the \\(\\mathbf{c} \\in [0,1]^g\\) is the vector of mixing proportions with \\(\\sum_{j=0}^g c_j = 1\\), while the \\(\\boldsymbol{\\Psi} = \\left( \\boldsymbol{\\theta}_1, \\ldots, \\boldsymbol{\\theta}_g\\right)\\) is the vector of all \\(g\\) models’ parameters. Note that we will implement our model such that some of the parameters in each \\(\\boldsymbol{\\theta}_j\\) are shared across the \\(g\\) components – namely the \\(t_{r \\rightarrow v}\\) corresponding to the blue arcs in figure 1.\nLet now \\(\\mathfrak{D} = \\left( \\mathbf{D}_1, \\ldots, \\mathbf{D}_s \\right)\\) be a dataset consisting of \\(s\\) subcohorts of patients. Within a subcohort \\(i\\) we find \\(N_i\\) patients with tumors in the same subsite. We can then introduce a latent variable \\(\\mathbf{Z}\\) with a one-hot-encoding: Basically, it can take on values \\(\\mathbf{z}_i \\in \\{ 0,1 \\}^g\\) with \\(z_{ij}=1\\) if subcohort \\(i\\) belongs to component \\(j\\) and \\(z_{ij}=0\\) else.\nThe latent variables are helpful in resolving the invariance of the likelihood w.r.t. permutations of the component labels, which may introduce problems, e.g. for common MCMC sampling methods. The \\(\\mathbf{Z}\\) allows us to derive two sets of interdependent equations that we may solve in an iterative fashion (see e.g. Bishop (2006) for a detailed derivation) that is commonly referred to as expectation-maximization (EM) algorithm:\nThe first set are the probabilities of subcohort \\(i\\) to belong to component \\(j\\), given a set of parameters \\(\\boldsymbol{\\Psi}^\\star\\). These are often called the responsibilities: \\[\n\\gamma (z_{ij}) = P \\left( z_{ij}=1 \\mid \\mathbf{D}_i , \\boldsymbol{\\Psi}^\\star, \\mathbf{c} \\right) = \\frac{ c_j P \\left( \\mathbf{D}_i \\mid \\boldsymbol{\\theta}_j^\\star \\right) }{\\sum_{k=0}^g c_k P \\left( \\mathbf{D}_i \\mid \\boldsymbol{\\theta}_k^\\star \\right)}\n\\]\nFrom this, we can compute new mixing proportions \\(c_j^\\star=\\sum_{i=1}^s \\gamma (z_{ij}) / s\\) and then infer new parameters \\(\\boldsymbol{\\Psi}^\\star\\) – e.g. via MCMC sampling – from the resulting likelihood, which is the second set:\n\\[\nP \\left( \\mathbf{D} \\mid \\boldsymbol{\\Psi}, \\mathbf{c}^\\star \\right) = \\sum_{j=0}^g c_j^\\star P \\left( \\mathbf{D} \\mid \\boldsymbol{\\theta}_j \\right)\n\\]"
  },
  {
    "objectID": "content/manuscript.html#sec-implementation",
    "href": "content/manuscript.html#sec-implementation",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Implementation",
    "text": "Implementation\nWe did this in this and that fashion…"
  },
  {
    "objectID": "content/manuscript.html#multi-centric-data",
    "href": "content/manuscript.html#multi-centric-data",
    "title": "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer",
    "section": "Multi-Centric Data",
    "text": "Multi-Centric Data\nFor the analyses in this work, we used five datasets from four different institutions:\n\n287 oropharyngeal patients from the University of Zurich in Swizerland\n263 oropharyngeal patients from the Centre Léon Bérard in Fance\n289 oropharyngeal and oral cavity patients from the Inselspital Bern in Swizerland\n239 oropharyngeal and oral cavity patients from the Centre Léon Bérard in Fance\n162 oropharyngeal patients from the Hospital Vall d’Hebron in Spain\n\n\n\n\n\n\n\nFigure 2: Prevalence of LNL involvement stratified by subsite. The subsites are sorted in ascending order by their prevalence of involvement in LNL II. Oral cavity subsites are plotted in shaed of blue, oropharynx subsites in shades of orange.\n\n\n\nThe data comes in the form of CSV tables and are – except for the last and most recent addition – publicly available (Ludwig, Hoffmann, Pouymayou, Däppen, et al. 2022; Ludwig et al. 2023) and may be interactively explored in our Lymphatic Progression eXplorer LyProX. Each row of these tables corresponds to one patient and details in which LNL metastatic involvement was found or not, according to different diagnostic and pathologic modalities.\nIn figure 2, we have plotted the prevalence of involvement in the four LNLs I, II, III, and IV stratified by the primary tumor’s subsite. We only included patients with tumors in the gum, floor of mouth, other/unspecified parts of the mouth, palate, oropharynx, tosil, base of tongue, and other/unspecified parts of tongue, resulting in 1242 patients."
  }
]